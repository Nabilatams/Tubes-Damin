{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvvvyuvvneir+fcQrQzZlO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"elZTuSKC7z6X","executionInfo":{"status":"ok","timestamp":1751120902322,"user_tz":-420,"elapsed":15379,"user":{"displayName":"Nabila Tam","userId":"16815138263817183372"}},"outputId":"752370f8-0b31-48ce-d980-9e8f9ba59e12"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-0f15ae88-62e6-4fcb-a720-0f1910759e51\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-0f15ae88-62e6-4fcb-a720-0f1910759e51\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving student_dataset.zip to student_dataset.zip\n"]},{"output_type":"execute_result","data":{"text/plain":["['Students Performance Dataset.json',\n"," '1_dashboard_overview.ipynb',\n"," '5_data_preprocessing.ipynb',\n"," '4_exploratory_data_analysis.ipynb',\n"," '6_modeling_evaluation.ipynb',\n"," 'Students_Grading_Dataset_Biased.json',\n"," 'Students_Grading_Dataset_Biased.csv',\n"," '2_business_understanding.ipynb',\n"," 'cleaned_data.csv',\n"," 'Students Performance Dataset.csv',\n"," '3_data_understanding.ipynb',\n"," 'scaler.pkl',\n"," 'metadata.xlsx',\n"," 'random_forest_model.pkl',\n"," 'logistic_model.pkl']"]},"metadata":{},"execution_count":1}],"source":["from google.colab import files\n","import zipfile\n","\n","# Upload file ZIP\n","uploaded = files.upload()\n","\n","# Ekstrak file ZIP\n","with zipfile.ZipFile(\"student_dataset.zip\", \"r\") as zip_ref:\n","    zip_ref.extractall(\"data\")\n","    import os\n","os.listdir(\"data\")"]},{"cell_type":"code","source":["!pip install streamlit pyngrok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMic77u_8E_h","executionInfo":{"status":"ok","timestamp":1751120944671,"user_tz":-420,"elapsed":12344,"user":{"displayName":"Nabila Tam","userId":"16815138263817183372"}},"outputId":"7b887a4f-bfda-442d-806a-b81f821fd7d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.44.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import joblib\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n","\n","# Setup page\n","st.set_page_config(page_title=\"Student Data Mining App\", layout=\"wide\")\n","\n","# Load data dan model\n","@st.cache_data\n","def load_data():\n","    df = pd.read_csv(\"data/cleaned_data.csv\")\n","    return df\n","\n","@st.cache_data\n","def load_raw_data():\n","    return pd.read_csv(\"data/Students Performance Dataset.csv\")\n","\n","@st.cache_resource\n","def load_models():\n","    rf = joblib.load(\"data/random_forest_model.pkl\")\n","    lr = joblib.load(\"data/logistic_model.pkl\")\n","    scaler = joblib.load(\"data/scaler.pkl\")\n","    return rf, lr, scaler\n","\n","df = load_data()\n","raw_df = load_raw_data()\n","rf_model, lr_model, scaler = load_models()\n","\n","# Navigasi halaman di header\n","halaman = st.selectbox(\n","    \"Navigasi Halaman\",\n","    [\n","        \"Dashboard Overview\",\n","        \"Business Understanding\",\n","        \"Data Understanding\",\n","        \"Exploratory Data Analysis\",\n","        \"Data Preprocessing\",\n","        \"Modeling & Evaluation\",\n","        \"Input Score for Prediction\"\n","    ],\n","    index=0\n",")\n","\n","# =================== Halaman 1: Dashboard Overview ===================\n","if halaman == \"Dashboard Overview\":\n","    st.markdown(\"<br><h1 style='text-align: center; color: #FF7272;'>Student Graduation Prediction</h1>\", unsafe_allow_html=True)\n","    st.markdown(\"<hr>\", unsafe_allow_html=True)\n","\n","    st.subheader(\"1. Tujuan Proyek\")\n","    st.write(\n","        \"\"\"\n","        Proyek ini bertujuan untuk membangun sistem yang dapat memprediksi kelulusan mahasiswa\n","        berdasarkan berbagai indikator performa akademik dan kebiasaan belajar mereka,\n","        seperti nilai ujian, kehadiran, partisipasi, hingga tingkat stres.\n","        \"\"\"\n","    )\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    st.subheader(\"2. Struktur & Tahapan Proyek\")\n","    st.markdown(\"\"\"\n","    Proyek ini disusun melalui beberapa tahapan penting, yaitu:\n","    - **1. Business Understanding**: Merumuskan tujuan bisnis dan manfaat dari prediksi kelulusan.\n","    - **2. Data Understanding**: Memahami struktur, kualitas, dan distribusi data.\n","    - **3. Exploratory Data Analysis (EDA)**: Menelusuri pola dan hubungan antar fitur.\n","    - **4. Data Preprocessing**: Membersihkan, menormalisasi, dan menyiapkan data untuk modeling.\n","    - **5. Modeling**: Menerapkan algoritma klasifikasi seperti Logistic Regression dan Random Forest.\n","    - **6. Evaluation**: Mengevaluasi performa model dengan metrik akurasi, presisi, recall, dan F1.\n","    - **7. Deployment**: Membuat antarmuka input dan menampilkan prediksi kelulusan secara interaktif.\n","    \"\"\")\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    st.subheader(\"3. Pendekatan & Model yang Digunakan\")\n","    st.write(\"\"\"\n","    - **Logistic Regression**: Untuk baseline prediksi kelulusan berbasis probabilitas linear.\n","    - **Random Forest**: Untuk meningkatkan akurasi prediksi dengan pendekatan ensemble learning.\n","    - **Cross Validation & Hyperparameter Tuning**: Untuk mengoptimalkan model Random Forest.\n","    \"\"\")\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    st.subheader(\"4. Anggota Kelompok\")\n","    data_anggota = {\n","        \"Nama\": [\"Anggota 1\", \"Anggota 2\", \"Anggota 3\"],\n","        \"NIM\": [\"12345678\", \"12345679\", \"12345680\"]\n","    }\n","    df_anggota = pd.DataFrame(data_anggota)\n","    st.dataframe(df_anggota, use_container_width=True)\n","\n","\n","# =================== Halaman 2: Business Understanding ===================\n","elif halaman == \"Business Understanding\":\n","    st.markdown(\"<br><h1 style='text-align: center; color: #FF7272;'>Business Understanding</h1>\", unsafe_allow_html=True)\n","    st.markdown(\"<hr>\", unsafe_allow_html=True)\n","\n","\n","    # Latar belakang\n","    st.subheader(\"1. Latar Belakang\")\n","    st.markdown(\"\"\"\n","    Sistem pendidikan modern menghadapi tantangan dalam mengidentifikasi siswa yang berisiko tidak lulus tepat waktu.\n","    Dengan meningkatnya jumlah data akademik yang tersedia, penting untuk memanfaatkannya guna membantu proses pengambilan keputusan\n","    dan perencanaan pendidikan yang lebih baik.\n","    \"\"\")\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Tujuan\n","    st.subheader(\"2. Tujuan\")\n","    st.markdown(\"\"\"\n","    - Mengidentifikasi siswa yang berisiko tidak lulus.\n","    - Memberikan wawasan kepada pendidik dan orang tua untuk memberikan intervensi lebih awal.\n","    - Meningkatkan efektivitas perencanaan akademik dan kebijakan pendidikan.\n","    \"\"\")\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Aspek penting proyek\n","    st.subheader(\"3. Aspek Penting dalam Proyek\")\n","    st.markdown(\"\"\"\n","    - Mengolah dataset akademik siswa secara bersih dan terstruktur.\n","    - Melakukan eksplorasi dan analisis mendalam terhadap fitur penentu kelulusan.\n","    - Menerapkan metode klasifikasi seperti Logistic Regression dan Random Forest.\n","    - Mengevaluasi performa model dengan metrik seperti akurasi, presisi, recall, dan f1-score.\n","    \"\"\")\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Manfaat aplikasi\n","    st.subheader(\"4. Manfaat Aplikasi\")\n","    st.markdown(\"\"\"\n","    - Membantu guru dan staf akademik dalam membuat strategi peningkatan prestasi.\n","    - Memberi gambaran visual tentang faktor yang paling berpengaruh terhadap kelulusan siswa.\n","    - Memberi siswa umpan balik berdasarkan data riil untuk meningkatkan performa mereka.\n","    \"\"\")\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Nilai keberhasilan model\n","    st.subheader(\"5. Nilai Keberhasilan Model\")\n","    st.markdown(\"\"\"\n","    - Akurasi prediksi melebihi baseline (misalnya, 70%).\n","    - Model mampu mengidentifikasi siswa yang gagal (recall tinggi pada kelas 'Fail').\n","    - Terdapat keseimbangan antara presisi dan recall, terutama untuk aplikasi nyata.\n","    \"\"\")\n","\n","# =================== Halaman 3: Data Understanding ===================\n","elif halaman == \"Data Understanding\":\n","    st.markdown(\"<br><h1 style='text-align: center; color: #FF7272;'>Data Understanding</h1>\", unsafe_allow_html=True)\n","    st.markdown(\"<hr>\", unsafe_allow_html=True)\n","\n","    # Preview Data\n","    st.subheader(\"1. Preview Dataset\")\n","    st.dataframe(raw_df.head())\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Shape\n","    st.subheader(\"2. Ukuran Dataset\")\n","    st.write(f\"Jumlah Baris: {raw_df.shape[0]}\")\n","    st.write(f\"Jumlah Kolom: {raw_df.shape[1]}\")\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Tipe Data\n","    st.subheader(\"3. Tipe Data Tiap Kolom\")\n","    st.dataframe(raw_df.dtypes.reset_index().rename(columns={'index': 'Kolom', 0: 'Tipe Data'}))\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Missing Values\n","    st.subheader(\"4. Missing Values\")\n","    missing = raw_df.isnull().sum()\n","    missing_df = pd.DataFrame({'Kolom': missing.index, 'Jumlah Missing': missing.values})\n","    st.dataframe(missing_df)\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Duplikat\n","    st.subheader(\"5. Duplikat\")\n","    total_duplicates = raw_df.duplicated().sum()\n","    st.write(f\"Jumlah Baris Duplikat: {total_duplicates}\")\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Statistik Deskriptif Kolom Numerik\n","    st.subheader(\"6. Statistik Deskriptif Kolom Numerik\")\n","    st.dataframe(raw_df.describe())\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Statistik Deskriptif Kolom Kategorikal\n","    st.subheader(\"7. Statistik Deskriptif Kolom Kategorikal\")\n","    st.dataframe(raw_df.describe(include='object'))\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # Jumlah Kemunculan Unique Data di Kolom Kategorikal (selain Student_ID dan Email)\n","    st.subheader(\"8. Jumlah Kemunculan Unique Data di Kolom Kategorikal (selain Student_ID dan Email)\")\n","\n","    categorical_columns = [\n","      'First_Name', 'Last_Name', 'Gender', 'Department', 'Grade',\n","      'Extracurricular_Activities', 'Internet_Access_at_Home',\n","      'Parent_Education_Level', 'Family_Income_Level'\n","    ]\n","\n","    if not categorical_columns:\n","        st.info(\"Tidak ada kolom kategorikal dengan kategori terbatas untuk ditampilkan.\")\n","    else:\n","        for col in categorical_columns:\n","          st.markdown(f\"**{col}**\")\n","          freq_df = raw_df[col].value_counts().reset_index()\n","          freq_df.columns = [col, 'Jumlah']\n","          st.dataframe(freq_df, use_container_width=True)\n","\n","# =================== Halaman 4: Exploratory Data Analysis ===================\n","elif halaman == \"Exploratory Data Analysis\":\n","    st.markdown(\"<br><h1 style='text-align: center; color: #FF7272;'>Exploratory Data Analysis</h1>\", unsafe_allow_html=True)\n","    st.markdown(\"<hr>\", unsafe_allow_html=True)\n","\n","    # Tambahkan kolom Class jika belum ada di raw_df\n","    if 'Class' not in raw_df.columns:\n","        raw_df['Class'] = raw_df['Total_Score'].apply(lambda x: 'Pass' if x >= 70 else 'Fail')\n","\n","    st.subheader(\"1. Label Unik dan Deskripsi Kelas\")\n","    unique_labels = raw_df['Class'].unique()\n","    st.write(f\"Label unik pada kolom 'Class': {unique_labels} → 'Fail' atau 'Pass'\")\n","\n","    st.subheader(\"2. Statistik Deskriptif Berdasarkan Kelas\")\n","    # Statistik Siswa yang Lulus (Class = 'Pass')\n","    st.subheader(\"Statistik Siswa yang Lulus (Class = 'Pass')\")\n","\n","    st.markdown(\"**Statistik Numerik:**\")\n","    st.dataframe(raw_df[raw_df['Class'] == 'Pass'].describe())\n","\n","    st.markdown(\"**Statistik Kategorikal:**\")\n","    st.dataframe(raw_df[raw_df['Class'] == 'Pass'].describe(include='object'))\n","\n","    # Statistik Siswa yang Tidak Lulus (Class = 'Fail')\n","    st.subheader(\"Statistik Siswa yang Tidak Lulus (Class = 'Fail')\")\n","\n","    st.markdown(\"**Statistik Numerik:**\")\n","    st.dataframe(raw_df[raw_df['Class'] == 'Fail'].describe())\n","\n","    st.markdown(\"**Statistik Kategorikal:**\")\n","    st.dataframe(raw_df[raw_df['Class'] == 'Fail'].describe(include='object'))\n","\n","    st.subheader(\"3. Pie Chart Distribusi Class (Fail vs Pass)\")\n","    class_counts = raw_df['Class'].value_counts()\n","    fig1, ax1 = plt.subplots()\n","    ax1.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%', startangle=90, colors=['salmon', 'skyblue'])\n","    ax1.axis('equal')\n","    st.pyplot(fig1)\n","\n","    st.subheader(\"4. Histogram Distribusi Tiap Fitur\")\n","    features = ['Projects_Score', 'Final_Score', 'Midterm_Score',\n","                'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score']\n","    for col in features:\n","        fig, ax = plt.subplots(figsize=(6, 4))\n","        sns.histplot(raw_df[col], kde=True, bins=30, ax=ax)\n","        ax.set_title(f'Distribusi Nilai: {col}')\n","        st.pyplot(fig)\n","\n","    st.subheader(\"5. Korelasi Antar Fitur Numerik\")\n","    corr_matrix = raw_df.select_dtypes(include='number').corr()\n","    st.dataframe(corr_matrix)\n","\n","    st.subheader(\"6. Heatmap Korelasi\")\n","    fig2, ax2 = plt.subplots(figsize=(10, 6))\n","    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax2)\n","    st.pyplot(fig2)\n","\n","    st.subheader(\"7. Korelasi terhadap Target (Class)\")\n","    # Encode Class agar bisa dihitung korelasinya\n","    raw_df['Class_binary'] = raw_df['Class'].map({'Pass': 1, 'Fail': 0})\n","    corr_target = raw_df.select_dtypes(include='number').corr()['Class_binary'].drop('Class_binary').sort_values(ascending=False)\n","    st.dataframe(corr_target)\n","\n","    fig3, ax3 = plt.subplots(figsize=(8, 5))\n","    sns.barplot(x=corr_target.values, y=corr_target.index, palette='crest', ax=ax3)\n","    ax3.set_title(\"Korelasi terhadap Target (Class)\")\n","    ax3.set_xlabel(\"Nilai Korelasi\")\n","    st.pyplot(fig3)\n","\n","    st.subheader(\"8. Pairplot Hubungan Antar Variabel\")\n","    import warnings\n","    warnings.filterwarnings(\"ignore\")\n","\n","    pairplot_df = raw_df[features + ['Class']].dropna().copy()\n","    pairplot_df['Class'] = pairplot_df['Class'].map({'Fail': 'Fail', 'Pass': 'Pass'})\n","\n","    fig4 = sns.pairplot(pairplot_df, hue='Class', diag_kind='kde', palette='Set2')\n","    st.pyplot(fig4.figure)\n","\n","# =================== Halaman 5: Data Preprocessing ===================\n","elif halaman == \"Data Preprocessing\":\n","    st.markdown(\"<br><h1 style='text-align: center; color: #FF7272;'>Data Preprocessing</h1>\", unsafe_allow_html=True)\n","    st.markdown(\"<hr>\", unsafe_allow_html=True)\n","\n","    st.subheader(\"1. Penjelasan Fitur yang Digunakan\")\n","    st.markdown(\"\"\"\n","    Dataset awal memiliki banyak kolom, namun hanya beberapa fitur yang dipilih berdasarkan korelasi terhadap kelulusan:\n","    - `Projects_Score`, `Final_Score`, `Midterm_Score`\n","    - `Assignments_Avg`, `Quizzes_Avg`, `Participation_Score`\n","    - `Class`: Label target (kelulusan)\n","    \"\"\")\n","\n","    st.subheader(\"2. Cek Missing Values Sebelum Pembersihan\")\n","    missing_raw = raw_df.isnull().sum()\n","    if missing_raw.sum() == 0:\n","        st.success(\"Tidak ada missing values.\")\n","    else:\n","        st.dataframe(missing_raw[missing_raw > 0])\n","\n","\n","    st.subheader(\"3. Cek Missing Values Setelah Pembersihan\")\n","    missing_clean = df.isnull().sum()\n","    if missing_clean.sum() == 0:\n","        st.success(\"Tidak ada missing values setelah data dibersihkan.\")\n","    else:\n","        st.dataframe(missing_clean[missing_clean > 0])\n","\n","    st.subheader(\"4. Cek Data Duplikat\")\n","    dup = raw_df.duplicated().sum()\n","    if dup > 0:\n","        st.warning(f\"Ada {dup} baris duplikat dalam data.\")\n","    else:\n","        st.success(\"Tidak ada baris duplikat.\")\n","\n","    st.subheader(\"5. Deteksi Outlier dan Visualisasi Boxplot\")\n","    outlier_cols = [\n","        'Attendance (%)', 'Midterm_Score', 'Final_Score', 'Projects_Score',\n","        'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score',\n","        'Total_Score', 'Study_Hours_per_Week', 'Sleep_Hours_per_Night', 'Stress_Level (1-10)'\n","    ]\n","\n","    for col in outlier_cols:\n","        if col in raw_df.columns:\n","            Q1 = raw_df[col].quantile(0.25)\n","            Q3 = raw_df[col].quantile(0.75)\n","            IQR = Q3 - Q1\n","            lower_bound = Q1 - 1.5 * IQR\n","            upper_bound = Q3 + 1.5 * IQR\n","            outlier_count = ((raw_df[col] < lower_bound) | (raw_df[col] > upper_bound)).sum()\n","\n","            st.markdown(f\"**{col}** → Jumlah Outlier: {outlier_count}\")\n","            fig, ax = plt.subplots(figsize=(6, 3))\n","            sns.boxplot(x=raw_df[col], ax=ax)\n","            st.pyplot(fig)\n","\n","    st.subheader(\"6. Encode Target `Class` (Pass/Fail)\")\n","    st.markdown(\"Label kelulusan `Class` telah diubah dari teks (`Pass`/`Fail`) menjadi angka (`1`/`0`).\")\n","\n","    if 'Class' not in raw_df.columns:\n","        raw_df['Class'] = raw_df['Total_Score'].apply(lambda x: 'Pass' if x >= 70 else 'Fail')\n","    class_dist = raw_df['Class'].value_counts().rename_axis('Class').reset_index(name='Jumlah')\n","    st.dataframe(class_dist)\n","\n","    st.write(\"Contoh encode:\")\n","    st.dataframe(df[['Projects_Score', 'Final_Score', 'Midterm_Score', 'Class']].head())\n","\n","    st.subheader(\"7. Hasil Akhir Setelah Scaling\")\n","    st.markdown(\"Dataset hasil preprocessing telah discaling menggunakan MinMaxScaler dan disimpan sebagai `cleaned_data.csv`.\")\n","    st.dataframe(df.head())\n","\n","    st.success(\"Data sudah siap digunakan untuk pemodelan.\")\n","\n","# =================== Halaman 6: Modeling & Evaluation ===================\n","elif halaman == \"Modeling & Evaluation\":\n","    st.markdown(\"<br><h1 style='text-align: center; color: #FF7272;'>Modeling & Evaluation</h1>\", unsafe_allow_html=True)\n","    st.markdown(\"<hr>\", unsafe_allow_html=True)\n","\n","    st.subheader(\"1. Preview Cleaned Dataset\")\n","    st.dataframe(df.head())\n","\n","    st.subheader(\"2. Penjelasan Splitting Data\")\n","    st.markdown(\"\"\"\n","    - Dataset dibagi menjadi 80% data latih dan 20% data uji menggunakan `train_test_split` dari `sklearn`.\n","    - Pembagian dilakukan dengan `stratify=y` agar distribusi kelas tetap seimbang antara train dan test.\n","    \"\"\")\n","\n","    st.subheader(\"3. Model yang Digunakan\")\n","    st.markdown(\"\"\"\n","    - **Logistic Regression** digunakan sebagai baseline model.\n","    - **Random Forest Classifier** digunakan untuk meningkatkan performa dengan metode ensemble.\n","    - Model yang digunakan berasal dari file `.pkl` hasil pelatihan sebelumnya (`logistic_model.pkl` dan `random_forest_model.pkl`).\n","    \"\"\")\n","\n","    st.subheader(\"4. Evaluasi Model Logistic Regression\")\n","\n","    # Pisahkan fitur dan target (ulang untuk halaman ini)\n","    X = df.drop(columns=[\"Class\"])\n","    y = df[\"Class\"]\n","\n","    # Split ulang dataset (konsisten dengan model training)\n","    from sklearn.model_selection import train_test_split\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42, stratify=y\n","    )\n","\n","    y_pred_lr = lr_model.predict(X_test)\n","    acc_lr = accuracy_score(y_test, y_pred_lr)\n","    prec_lr = precision_score(y_test, y_pred_lr)\n","    rec_lr = recall_score(y_test, y_pred_lr)\n","    f1_lr = f1_score(y_test, y_pred_lr)\n","\n","    st.write(f\"Akurasi  : {acc_lr:.4f}\")\n","    st.write(f\"Presisi  : {prec_lr:.4f}\")\n","    st.write(f\"Recall   : {rec_lr:.4f}\")\n","    st.write(f\"F1-score : {f1_lr:.4f}\")\n","    st.text(classification_report(y_test, y_pred_lr))\n","\n","    cm_lr = confusion_matrix(y_test, y_pred_lr)\n","    fig_lr, ax_lr = plt.subplots()\n","    sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=ax_lr)\n","    ax_lr.set_title(\"Logistic Regression - Confusion Matrix\")\n","    st.pyplot(fig_lr)\n","\n","    st.subheader(\"5. Evaluasi Model Random Forest\")\n","\n","    # Pisahkan fitur dan target (ulang untuk halaman ini)\n","    X = df.drop(columns=[\"Class\"])\n","    y = df[\"Class\"]\n","\n","    # Split ulang dataset (konsisten dengan model training)\n","    from sklearn.model_selection import train_test_split\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42, stratify=y\n","    )\n","\n","    # Prediksi & Evaluasi\n","    y_pred_rf = rf_model.predict(X_test)\n","    acc_rf = accuracy_score(y_test, y_pred_rf)\n","    prec_rf = precision_score(y_test, y_pred_rf)\n","    rec_rf = recall_score(y_test, y_pred_rf)\n","    f1_rf = f1_score(y_test, y_pred_rf)\n","\n","    # Tampilkan metrik\n","    st.write(f\"**Akurasi**  : {acc_rf:.4f}\")\n","    st.write(f\"**Presisi**  : {prec_rf:.4f}\")\n","    st.write(f\"**Recall**   : {rec_rf:.4f}\")\n","    st.write(f\"**F1-score** : {f1_rf:.4f}\")\n","\n","    # Classification Report\n","    st.text(\"Classification Report:\")\n","    st.text(classification_report(y_test, y_pred_rf))\n","\n","    # Confusion Matrix\n","    st.write(\"Confusion Matrix:\")\n","    cm_rf = confusion_matrix(y_test, y_pred_rf)\n","    fig_rf, ax_rf = plt.subplots()\n","    sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=ax_rf)\n","    ax_rf.set_xlabel(\"Predicted\")\n","    ax_rf.set_ylabel(\"Actual\")\n","    ax_rf.set_title(\"Random Forest - Confusion Matrix\")\n","    st.pyplot(fig_rf)\n","\n","    # Visualisasi Feature Importance\n","    st.subheader(\"6. Visualisasi Feature Importance (Random Forest)\")\n","    importance = pd.DataFrame({\n","        'Fitur': X.columns,\n","        'Importance': rf_model.feature_importances_\n","    }).sort_values(by='Importance', ascending=False)\n","\n","    fig_imp, ax_imp = plt.subplots(figsize=(8, 5))\n","    sns.barplot(data=importance, x='Importance', y='Fitur', palette='viridis', ax=ax_imp)\n","    ax_imp.set_title(\"Feature Importance - Random Forest\")\n","    st.pyplot(fig_imp)\n","\n","# =================== Halaman 7: Input Score for Prediction ===================\n","elif halaman == \"Input Score for Prediction\":\n","    st.markdown(\"<br><h1 style='text-align: center; color: #FF7272;'>Input Score for Prediction</h1>\", unsafe_allow_html=True)\n","    st.markdown(\"<hr>\", unsafe_allow_html=True)\n","\n","    st.write(\"Masukkan nilai-nilai berikut untuk memprediksi kemungkinan kelulusan mahasiswa:\")\n","\n","    # Input user via slider\n","    # input_data = {}\n","    # input_data['Projects_Score'] = st.slider(\"Projects Score\", 0.0, 100.0, 75.0)\n","    # input_data['Final_Score'] = st.slider(\"Final Score\", 0.0, 100.0, 75.0)\n","    # input_data['Midterm_Score'] = st.slider(\"Midterm Score\", 0.0, 100.0, 75.0)\n","    # input_data['Assignments_Avg'] = st.slider(\"Assignments Average\", 0.0, 100.0, 75.0)\n","    # input_data['Quizzes_Avg'] = st.slider(\"Quizzes Average\", 0.0, 100.0, 75.0)\n","    # input_data['Participation_Score'] = st.slider(\"Participation Score\", 0.0, 100.0, 75.0)\n","\n","    # Input user via keyboard\n","    input_data = {}\n","    input_data['Projects_Score'] = st.number_input(\"Projects Score\", min_value=0.0, max_value=100.0, value=75.0)\n","    input_data['Final_Score'] = st.number_input(\"Final Score\", min_value=0.0, max_value=100.0, value=75.0)\n","    input_data['Midterm_Score'] = st.number_input(\"Midterm Score\", min_value=0.0, max_value=100.0, value=75.0)\n","    input_data['Assignments_Avg'] = st.number_input(\"Assignments Average\", min_value=0.0, max_value=100.0, value=75.0)\n","    input_data['Quizzes_Avg'] = st.number_input(\"Quizzes Average\", min_value=0.0, max_value=100.0, value=75.0)\n","    input_data['Participation_Score'] = st.number_input(\"Participation Score\", min_value=0.0, max_value=100.0, value=75.0)\n","\n","\n","    input_df = pd.DataFrame([input_data])\n","\n","    st.subheader(\"1. Input Data yang Dimasukkan:\")\n","    st.dataframe(input_df)\n","\n","    # Scaling input\n","    input_scaled = scaler.transform(input_df)\n","\n","    # Prediksi dengan kedua model\n","    pred_lr = lr_model.predict(input_scaled)[0]\n","    pred_rf = rf_model.predict(input_scaled)[0]\n","\n","    pred_text_lr = \"LULUS (PASS)\" if pred_lr == 1 else \"TIDAK LULUS (FAIL)\"\n","    pred_text_rf = \"LULUS (PASS)\" if pred_rf == 1 else \"TIDAK LULUS (FAIL)\"\n","\n","    st.subheader(\"2. Hasil Prediksi:\")\n","    col1, col2 = st.columns(2)\n","    with col1:\n","        st.markdown(\"**Logistic Regression**\")\n","        st.success(pred_text_lr if pred_lr == 1 else pred_text_lr)\n","\n","    with col2:\n","        st.markdown(\"**Random Forest**\")\n","        st.success(pred_text_rf if pred_rf == 1 else pred_text_rf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWkMzLRb8G4V","executionInfo":{"status":"ok","timestamp":1751120944923,"user_tz":-420,"elapsed":243,"user":{"displayName":"Nabila Tam","userId":"16815138263817183372"}},"outputId":"e0093608-bd65-47ef-80c1-270e6e7d3f05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","source":["!ngrok config add-authtoken 2ynqi8VAsqDonVPIVk4QkSPnNbH_57kHX8Drhfas3qJtf5NBi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6jTGCc28JCC","executionInfo":{"status":"ok","timestamp":1751120956372,"user_tz":-420,"elapsed":1019,"user":{"displayName":"Nabila Tam","userId":"16815138263817183372"}},"outputId":"282f9d17-03d5-4798-d072-06835e8fca52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}]},{"cell_type":"code","source":["import subprocess\n","import time\n","from pyngrok import ngrok\n","\n","!pkill -f streamlit\n","!pkill -f ngrok\n","\n","# Jalankan Streamlit\n","process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n","\n","# Tunggu streamlit siap\n","time.sleep(5)\n","\n","# Buka tunnel\n","url = ngrok.connect(8501)\n","print(f\" Akses Dashboard Streamlit di sini: {url}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYpzk6Br8KVw","executionInfo":{"status":"ok","timestamp":1751121287783,"user_tz":-420,"elapsed":5410,"user":{"displayName":"Nabila Tam","userId":"16815138263817183372"}},"outputId":"c850a42e-f38d-4511-9cfc-a00a1429a5f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Akses Dashboard Streamlit di sini: NgrokTunnel: \"https://7515-35-186-169-198.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]}]}