# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VPg8QtxDQlB0DWJ8Pc1maxwjIqIqmXhz
"""

from google.colab import files
import zipfile

# Upload file ZIP
uploaded = files.upload()

# Ekstrak file ZIP
with zipfile.ZipFile("student_dataset.zip", "r") as zip_ref:
    zip_ref.extractall("data")
    import os
os.listdir("data")

!pip install streamlit pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# import joblib
# from sklearn.cluster import KMeans
# from sklearn.decomposition import PCA
# from sklearn.metrics import silhouette_score
# 
# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
# 
# # Setup page
# st.set_page_config(page_title="Student Data Mining App", layout="wide")
# 
# # Load data dan model
# @st.cache_data
# def load_data():
#     df = pd.read_csv("data/cleaned_data.csv")
#     return df
# 
# @st.cache_data
# def load_raw_data():
#     return pd.read_csv("data/Students Performance Dataset.csv")
# 
# @st.cache_resource
# def load_models():
#     rf = joblib.load("data/random_forest_model.pkl")
#     lr = joblib.load("data/logistic_model.pkl")
#     scaler = joblib.load("data/scaler.pkl")
#     kmeans = joblib.load("data/kmeans_model.pkl")
#     return rf, lr, scaler, kmeans
# 
# df = load_data()
# raw_df = load_raw_data()
# rf_model, lr_model, scaler, kmeans = load_models()
# 
# # Navigasi halaman di header
# halaman = st.selectbox(
#     "Navigasi Halaman",
#     [
#         "Dashboard Overview",
#         "Business Understanding",
#         "Data Understanding",
#         "Exploratory Data Analysis",
#         "Data Preprocessing",
#         "Modeling & Evaluation",
#         "Input Score for Prediction"
#     ],
#     index=0
# )
# 
# # =================== Halaman 1: Dashboard Overview ===================
# if halaman == "Dashboard Overview":
#     st.markdown("<br><h1 style='text-align: center; color: #FF7272;'>Student Graduation Prediction</h1>", unsafe_allow_html=True)
#     st.markdown("<hr>", unsafe_allow_html=True)
# 
#     st.subheader("1. Tujuan Proyek")
#     st.write(
#         """
#         Proyek ini bertujuan untuk membangun sistem yang dapat memprediksi kelulusan mahasiswa
#         berdasarkan berbagai indikator performa akademik dan kebiasaan belajar mereka,
#         seperti nilai ujian, kehadiran, partisipasi, hingga tingkat stres.
#         """
#     )
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     st.subheader("2. Struktur & Tahapan Proyek")
#     st.markdown("""
#     Proyek ini disusun melalui beberapa tahapan penting, yaitu:
#     - **1. Business Understanding**: Merumuskan tujuan bisnis dan manfaat dari prediksi kelulusan.
#     - **2. Data Understanding**: Memahami struktur, kualitas, dan distribusi data.
#     - **3. Exploratory Data Analysis (EDA)**: Menelusuri pola dan hubungan antar fitur.
#     - **4. Data Preprocessing**: Membersihkan, menormalisasi, dan menyiapkan data untuk modeling.
#     - **5. Modeling**: Menerapkan algoritma klasifikasi seperti Logistic Regression dan Random Forest.
#     - **6. Evaluation**: Mengevaluasi performa model dengan metrik akurasi, presisi, recall, dan F1.
#     - **7. Deployment**: Membuat antarmuka input dan menampilkan prediksi kelulusan secara interaktif.
#     """)
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     st.subheader("3. Pendekatan & Model yang Digunakan")
#     st.write("""
#     - **Logistic Regression**: Untuk baseline prediksi kelulusan berbasis probabilitas linear.
#     - **Random Forest**: Untuk meningkatkan akurasi prediksi dengan pendekatan ensemble learning.
#     - **K-Means**: Model clustering yang digunakan untuk segmentasi siswa.
#     """)
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     st.subheader("4. Anggota Kelompok")
#     data_anggota = {
#         "Nama": ["Difa Ramadhan", "Nabila Tsari Aulia Mahmudah ", "Siti Arfi Mutoharoh"],
#         "NIM": ["220102023", "220102064", "220102082"]
#     }
#     df_anggota = pd.DataFrame(data_anggota)
#     st.dataframe(df_anggota, use_container_width=True)
# 
# 
# # =================== Halaman 2: Business Understanding ===================
# elif halaman == "Business Understanding":
#     st.markdown("<br><h1 style='text-align: center; color: #FF7272;'>Business Understanding</h1>", unsafe_allow_html=True)
#     st.markdown("<hr>", unsafe_allow_html=True)
# 
# 
#     # Latar belakang
#     st.subheader("1. Latar Belakang")
#     st.markdown("""
#     Sistem pendidikan modern menghadapi tantangan dalam mengidentifikasi siswa yang berisiko tidak lulus tepat waktu.
#     Dengan meningkatnya jumlah data akademik yang tersedia, penting untuk memanfaatkannya guna membantu proses pengambilan keputusan
#     dan perencanaan pendidikan yang lebih baik.
#     """)
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Tujuan
#     st.subheader("2. Tujuan")
#     st.markdown("""
#     - Mengidentifikasi siswa yang berisiko tidak lulus.
#     - Memberikan wawasan kepada pendidik dan orang tua untuk memberikan intervensi lebih awal.
#     - Meningkatkan efektivitas perencanaan akademik dan kebijakan pendidikan.
#     """)
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Aspek penting proyek
#     st.subheader("3. Aspek Penting dalam Proyek")
#     st.markdown("""
#     - Mengolah dataset akademik siswa secara bersih dan terstruktur.
#     - Melakukan eksplorasi dan analisis mendalam terhadap fitur penentu kelulusan.
#     - Menerapkan metode klasifikasi seperti Logistic Regression dan Random Forest.
#     - Mengevaluasi performa model dengan metrik seperti akurasi, presisi, recall, dan f1-score.
#     """)
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Manfaat aplikasi
#     st.subheader("4. Manfaat Aplikasi")
#     st.markdown("""
#     - Membantu guru dan staf akademik dalam membuat strategi peningkatan prestasi.
#     - Memberi gambaran visual tentang faktor yang paling berpengaruh terhadap kelulusan siswa.
#     - Memberi siswa umpan balik berdasarkan data riil untuk meningkatkan performa mereka.
#     """)
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Nilai keberhasilan model
#     st.subheader("5. Nilai Keberhasilan Model")
#     st.markdown("""
#     - Akurasi prediksi melebihi baseline (misalnya, 70%).
#     - Model mampu mengidentifikasi siswa yang gagal (recall tinggi pada kelas 'Fail').
#     - Terdapat keseimbangan antara presisi dan recall, terutama untuk aplikasi nyata.
#     """)
# 
# # =================== Halaman 3: Data Understanding ===================
# elif halaman == "Data Understanding":
#     st.markdown("<br><h1 style='text-align: center; color: #FF7272;'>Data Understanding</h1>", unsafe_allow_html=True)
#     st.markdown("<hr>", unsafe_allow_html=True)
# 
#     # Preview Data
#     st.subheader("1. Preview Dataset")
#     st.dataframe(raw_df.head())
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Shape
#     st.subheader("2. Ukuran Dataset")
#     st.write(f"Jumlah Baris: {raw_df.shape[0]}")
#     st.write(f"Jumlah Kolom: {raw_df.shape[1]}")
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Tipe Data
#     st.subheader("3. Tipe Data Tiap Kolom")
#     st.dataframe(raw_df.dtypes.reset_index().rename(columns={'index': 'Kolom', 0: 'Tipe Data'}))
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Missing Values
#     st.subheader("4. Missing Values")
#     missing = raw_df.isnull().sum()
#     missing_df = pd.DataFrame({'Kolom': missing.index, 'Jumlah Missing': missing.values})
#     st.dataframe(missing_df)
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Duplikat
#     st.subheader("5. Duplikat")
#     total_duplicates = raw_df.duplicated().sum()
#     st.write(f"Jumlah Baris Duplikat: {total_duplicates}")
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Statistik Deskriptif Kolom Numerik
#     st.subheader("6. Statistik Deskriptif Kolom Numerik")
#     st.dataframe(raw_df.describe())
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Statistik Deskriptif Kolom Kategorikal
#     st.subheader("7. Statistik Deskriptif Kolom Kategorikal")
#     st.dataframe(raw_df.describe(include='object'))
# 
#     st.markdown("<br>", unsafe_allow_html=True)
# 
#     # Jumlah Kemunculan Unique Data di Kolom Kategorikal
#     st.subheader("8. Jumlah Kemunculan Unique Data di Kolom Kategorikal")
# 
#     categorical_columns = [
#       'First_Name', 'Last_Name', 'Gender', 'Department', 'Grade',
#       'Extracurricular_Activities', 'Internet_Access_at_Home',
#       'Parent_Education_Level', 'Family_Income_Level'
#     ]
# 
#     if not categorical_columns:
#         st.info("Tidak ada kolom kategorikal dengan kategori terbatas untuk ditampilkan.")
#     else:
#         for col in categorical_columns:
#           st.markdown(f"**{col}**")
#           freq_df = raw_df[col].value_counts().reset_index()
#           freq_df.columns = [col, 'Jumlah']
#           st.dataframe(freq_df, use_container_width=True)
# 
# # =================== Halaman 4: Exploratory Data Analysis ===================
# elif halaman == "Exploratory Data Analysis":
#     st.markdown("<br><h1 style='text-align: center; color: #FF7272;'>Exploratory Data Analysis</h1>", unsafe_allow_html=True)
#     st.markdown("<hr>", unsafe_allow_html=True)
# 
#     # Tambahkan kolom Class jika belum ada di raw_df
#     if 'Class' not in raw_df.columns:
#         raw_df['Class'] = raw_df['Total_Score'].apply(lambda x: 'Pass' if x >= 70 else 'Fail')
# 
#     st.subheader("1. Label Unik dan Deskripsi Kelas")
#     unique_labels = raw_df['Class'].unique()
#     st.write(f"Label unik pada kolom 'Class': {unique_labels} → 'Fail' atau 'Pass'")
# 
#     st.subheader("2. Statistik Deskriptif Berdasarkan Kelas")
#     # Statistik Siswa yang Lulus (Class = 'Pass')
#     st.subheader("Statistik Siswa yang Lulus (Class = 'Pass')")
# 
#     st.markdown("**Statistik Numerik:**")
#     st.dataframe(raw_df[raw_df['Class'] == 'Pass'].describe())
# 
#     st.markdown("**Statistik Kategorikal:**")
#     st.dataframe(raw_df[raw_df['Class'] == 'Pass'].describe(include='object'))
# 
#     # Statistik Siswa yang Tidak Lulus (Class = 'Fail')
#     st.subheader("Statistik Siswa yang Tidak Lulus (Class = 'Fail')")
# 
#     st.markdown("**Statistik Numerik:**")
#     st.dataframe(raw_df[raw_df['Class'] == 'Fail'].describe())
# 
#     st.markdown("**Statistik Kategorikal:**")
#     st.dataframe(raw_df[raw_df['Class'] == 'Fail'].describe(include='object'))
# 
#     st.subheader("3. Pie Chart Distribusi Class (Fail vs Pass)")
#     class_counts = raw_df['Class'].value_counts()
#     fig1, ax1 = plt.subplots()
#     ax1.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%', startangle=90, colors=['salmon', 'skyblue'])
#     ax1.axis('equal')
#     st.pyplot(fig1)
# 
#     st.subheader("4. Histogram Distribusi Tiap Fitur")
#     features = ['Projects_Score', 'Final_Score', 'Midterm_Score',
#                 'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score']
#     for col in features:
#         fig, ax = plt.subplots(figsize=(6, 4))
#         sns.histplot(raw_df[col], kde=True, bins=30, ax=ax)
#         ax.set_title(f'Distribusi Nilai: {col}')
#         st.pyplot(fig)
# 
#     st.subheader("5. Korelasi Antar Fitur Numerik")
#     corr_matrix = raw_df.select_dtypes(include='number').corr()
#     st.dataframe(corr_matrix)
# 
#     st.subheader("6. Heatmap Korelasi")
#     fig2, ax2 = plt.subplots(figsize=(10, 6))
#     sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax2)
#     st.pyplot(fig2)
# 
#     st.subheader("7. Korelasi terhadap Target (Class)")
#     # Encode Class agar bisa dihitung korelasinya
#     raw_df['Class_binary'] = raw_df['Class'].map({'Pass': 1, 'Fail': 0})
#     corr_target = raw_df.select_dtypes(include='number').corr()['Class_binary'].drop('Class_binary').sort_values(ascending=False)
#     st.dataframe(corr_target)
# 
#     fig3, ax3 = plt.subplots(figsize=(8, 5))
#     sns.barplot(x=corr_target.values, y=corr_target.index, palette='crest', ax=ax3)
#     ax3.set_title("Korelasi terhadap Target (Class)")
#     ax3.set_xlabel("Nilai Korelasi")
#     st.pyplot(fig3)
# 
#     st.subheader("8. Pairplot Hubungan Antar Variabel")
#     import warnings
#     warnings.filterwarnings("ignore")
# 
#     pairplot_df = raw_df[features + ['Class']].dropna().copy()
#     pairplot_df['Class'] = pairplot_df['Class'].map({'Fail': 'Fail', 'Pass': 'Pass'})
# 
#     fig4 = sns.pairplot(pairplot_df, hue='Class', diag_kind='kde', palette='Set2')
#     st.pyplot(fig4.figure)
# 
# # =================== Halaman 5: Data Preprocessing ===================
# elif halaman == "Data Preprocessing":
#     st.markdown("<br><h1 style='text-align: center; color: #FF7272;'>Data Preprocessing</h1>", unsafe_allow_html=True)
#     st.markdown("<hr>", unsafe_allow_html=True)
# 
#     st.subheader("1. Penjelasan Fitur yang Digunakan")
#     st.markdown("""
#     Dataset awal memiliki banyak kolom, namun hanya beberapa fitur yang dipilih berdasarkan korelasi terhadap kelulusan:
#     - `Projects_Score`, `Final_Score`, `Midterm_Score`
#     - `Assignments_Avg`, `Quizzes_Avg`, `Participation_Score`
#     - `Class`: Label target (kelulusan)
#     """)
# 
#     st.subheader("2. Cek Missing Values Sebelum Pembersihan")
#     missing_raw = raw_df.isnull().sum()
#     if missing_raw.sum() == 0:
#         st.success("Tidak ada missing values.")
#     else:
#         st.dataframe(missing_raw[missing_raw > 0])
# 
# 
#     st.subheader("3. Cek Missing Values Setelah Pembersihan")
#     missing_clean = df.isnull().sum()
#     if missing_clean.sum() == 0:
#         st.success("Tidak ada missing values setelah data dibersihkan.")
#     else:
#         st.dataframe(missing_clean[missing_clean > 0])
# 
#     st.subheader("4. Cek Data Duplikat")
#     dup = raw_df.duplicated().sum()
#     if dup > 0:
#         st.warning(f"Ada {dup} baris duplikat dalam data.")
#     else:
#         st.success("Tidak ada baris duplikat.")
# 
#     st.subheader("5. Deteksi Outlier dan Visualisasi Boxplot")
#     outlier_cols = [
#         'Attendance (%)', 'Midterm_Score', 'Final_Score', 'Projects_Score',
#         'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score',
#         'Total_Score', 'Study_Hours_per_Week', 'Sleep_Hours_per_Night', 'Stress_Level (1-10)'
#     ]
# 
#     for col in outlier_cols:
#         if col in raw_df.columns:
#             Q1 = raw_df[col].quantile(0.25)
#             Q3 = raw_df[col].quantile(0.75)
#             IQR = Q3 - Q1
#             lower_bound = Q1 - 1.5 * IQR
#             upper_bound = Q3 + 1.5 * IQR
#             outlier_count = ((raw_df[col] < lower_bound) | (raw_df[col] > upper_bound)).sum()
# 
#             st.markdown(f"**{col}** → Jumlah Outlier: {outlier_count}")
#             fig, ax = plt.subplots(figsize=(6, 3))
#             sns.boxplot(x=raw_df[col], ax=ax)
#             st.pyplot(fig)
# 
#     st.subheader("6. Encode Target `Class` (Pass/Fail)")
#     st.markdown("Label kelulusan `Class` telah diubah dari teks (`Pass`/`Fail`) menjadi angka (`1`/`0`).")
# 
#     if 'Class' not in raw_df.columns:
#         raw_df['Class'] = raw_df['Total_Score'].apply(lambda x: 'Pass' if x >= 70 else 'Fail')
#     class_dist = raw_df['Class'].value_counts().rename_axis('Class').reset_index(name='Jumlah')
#     st.dataframe(class_dist)
# 
#     st.write("Contoh encode:")
#     st.dataframe(df[['Projects_Score', 'Final_Score', 'Midterm_Score', 'Class']].head())
# 
#     st.subheader("7. Hasil Akhir Setelah Scaling")
#     st.markdown("Dataset hasil preprocessing telah discaling menggunakan MinMaxScaler dan disimpan sebagai `cleaned_data.csv`.")
#     st.dataframe(df.head())
# 
#     st.success("Data sudah siap digunakan untuk pemodelan.")
# 
# # =================== Halaman 6: Modeling & Evaluation ===================
# elif halaman == "Modeling & Evaluation":
#     st.markdown("<br><h1 style='text-align: center; color: #FF7272;'>Modeling & Evaluation</h1>", unsafe_allow_html=True)
#     st.markdown("<hr>", unsafe_allow_html=True)
# 
#     st.subheader("1. Preview Cleaned Dataset")
#     st.dataframe(df.head())
# 
#     st.subheader("2. Penjelasan Splitting Data")
#     st.markdown("""
#     - Dataset dibagi menjadi 80% data latih dan 20% data uji menggunakan `train_test_split` dari `sklearn`.
#     - Pembagian dilakukan dengan `stratify=y` agar distribusi kelas tetap seimbang antara train dan test.
#     """)
# 
#     st.subheader("3. Model yang Digunakan")
#     st.markdown("""
#    **Logistic Regression**
# - Logistic Regression merupakan algoritma klasifikasi statistik yang digunakan untuk memprediksi probabilitas suatu kejadian dengan pendekatan fungsi logistik (sigmoid).
# - Cocok digunakan untuk prediksi biner seperti kelulusan (Pass/Fail).
# - Model ini memberikan baseline yang baik karena kesederhanaannya dan interpretabilitasnya.
# 
# **Random Forest Classifier**
# - Random Forest adalah algoritma ensemble learning yang membangun banyak pohon keputusan (decision trees) dan menggabungkan hasilnya.
# - Memiliki akurasi tinggi, tahan terhadap overfitting, dan mampu menangani data kompleks serta non-linear.
# - Cocok untuk prediksi kelulusan karena mempertimbangkan banyak variabel dengan interaksi yang kompleks.
# 
# **K-Means Clustering**
# - K-Means merupakan metode unsupervised learning yang mengelompokkan data berdasarkan kemiripan fitur ke dalam sejumlah `k` cluster.
# - Dalam proyek ini, K-Means digunakan untuk mengelompokkan mahasiswa berdasarkan pola nilai mereka, terlepas dari label kelulusan.
# - Hasil clustering memberikan wawasan tambahan mengenai karakteristik kelompok mahasiswa, misalnya:
#   - Cluster siswa berprestasi tinggi,
#   - Cluster siswa berisiko gagal,
#   - dan Cluster dengan performa sedang.
#     """)
# 
#     st.subheader("4. Evaluasi Model Logistic Regression")
# 
#     # Pisahkan fitur dan target (ulang untuk halaman ini)
#     X = df.drop(columns=["Class"])
#     y = df["Class"]
# 
#     # Split ulang dataset (konsisten dengan model training)
#     from sklearn.model_selection import train_test_split
#     X_train, X_test, y_train, y_test = train_test_split(
#         X, y, test_size=0.2, random_state=42, stratify=y
#     )
# 
#     y_pred_lr = lr_model.predict(X_test)
#     acc_lr = accuracy_score(y_test, y_pred_lr)
#     prec_lr = precision_score(y_test, y_pred_lr)
#     rec_lr = recall_score(y_test, y_pred_lr)
#     f1_lr = f1_score(y_test, y_pred_lr)
# 
#     st.write(f"Akurasi  : {acc_lr:.4f}")
#     st.write(f"Presisi  : {prec_lr:.4f}")
#     st.write(f"Recall   : {rec_lr:.4f}")
#     st.write(f"F1-score : {f1_lr:.4f}")
#     st.text(classification_report(y_test, y_pred_lr))
# 
#     cm_lr = confusion_matrix(y_test, y_pred_lr)
#     fig_lr, ax_lr = plt.subplots()
#     sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=ax_lr)
#     ax_lr.set_title("Logistic Regression - Confusion Matrix")
#     st.pyplot(fig_lr)
# 
#     st.subheader("5. Evaluasi Model Random Forest")
# 
#     # Pisahkan fitur dan target (ulang untuk halaman ini)
#     X = df.drop(columns=["Class"])
#     y = df["Class"]
# 
#     # Split ulang dataset (konsisten dengan model training)
#     from sklearn.model_selection import train_test_split
#     X_train, X_test, y_train, y_test = train_test_split(
#         X, y, test_size=0.2, random_state=42, stratify=y
#     )
# 
#     # Prediksi & Evaluasi
#     y_pred_rf = rf_model.predict(X_test)
#     acc_rf = accuracy_score(y_test, y_pred_rf)
#     prec_rf = precision_score(y_test, y_pred_rf)
#     rec_rf = recall_score(y_test, y_pred_rf)
#     f1_rf = f1_score(y_test, y_pred_rf)
# 
#     # Tampilkan metrik
#     st.write(f"**Akurasi**  : {acc_rf:.4f}")
#     st.write(f"**Presisi**  : {prec_rf:.4f}")
#     st.write(f"**Recall**   : {rec_rf:.4f}")
#     st.write(f"**F1-score** : {f1_rf:.4f}")
# 
#     # Classification Report
#     st.text("Classification Report:")
#     st.text(classification_report(y_test, y_pred_rf))
# 
#     # Confusion Matrix
#     st.write("Confusion Matrix:")
#     cm_rf = confusion_matrix(y_test, y_pred_rf)
#     fig_rf, ax_rf = plt.subplots()
#     sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=ax_rf)
#     ax_rf.set_xlabel("Predicted")
#     ax_rf.set_ylabel("Actual")
#     ax_rf.set_title("Random Forest - Confusion Matrix")
#     st.pyplot(fig_rf)
# 
#     # Visualisasi Feature Importance
#     st.subheader("6. Visualisasi Feature Importance (Random Forest)")
#     importance = pd.DataFrame({
#         'Fitur': X.columns,
#         'Importance': rf_model.feature_importances_
#     }).sort_values(by='Importance', ascending=False)
# 
#     fig_imp, ax_imp = plt.subplots(figsize=(8, 5))
#     sns.barplot(data=importance, x='Importance', y='Fitur', palette='viridis', ax=ax_imp)
#     ax_imp.set_title("Feature Importance - Random Forest")
#     st.pyplot(fig_imp)
# 
#     # # Elbow Method untuk menentukan jumlah cluster
#     # st.subheader("7. Penentuan Jumlah Cluster dengan Elbow Method")
# 
#     # # X_clust = df.drop(columns='Class')
# 
#     # # inertias = []
#     # # silhouette_scores = []
#     # # K = range(1, 11)
# 
#     # # for k in K:
#     # #     km = KMeans(n_clusters=k, random_state=42)
#     # #     km.fit(X_clust)
#     # #     inertias.append(km.inertia_)
#     # #     if k > 1:
#     # #         labels = km.predict(X_clust)
#     # #         silhouette_scores.append(silhouette_score(X_clust, labels))
#     # #     else:
#     # #         silhouette_scores.append(np.nan)
# 
#     # # # Elbow plot
#     # # fig_elbow, ax_elbow = plt.subplots()
#     # # ax_elbow.plot(K, inertias, marker='o')
#     # # ax_elbow.set_xlabel('Jumlah Cluster (k)')
#     # # ax_elbow.set_ylabel('Inertia (SSE)')
#     # # ax_elbow.set_title('Elbow Method untuk Menentukan Cluster Optimal')
#     # # st.pyplot(fig_elbow)
# 
#     # # # Tabel Silhouette
#     # # results_df = pd.DataFrame({
#     # #     "Jumlah Cluster (k)": list(K),
#     # #     "Silhouette Score": silhouette_scores
#     # # })
#     # # st.subheader("Tabel Silhouette Score")
#     # # st.dataframe(results_df)
# 
#     # st.image("elbow_plot.png", caption="Elbow Method untuk Menentukan Jumlah Cluster", use_column_width=True)
# 
#     # # Interpretasi
#     # st.markdown("""
#     # Jumlah klaster yang dipilih dalam proses K-Means Clustering adalah tiga (k=3).
#     # Meskipun nilai Silhouette Score tertinggi terdapat pada k=2 (0.4034),
#     # perbedaan skor dengan k=3 (0.3982) relatif kecil.
#     # Pemilihan tiga klaster memberikan segmentasi yang lebih informatif,
#     # memungkinkan pengelompokan mahasiswa ke dalam kategori berprestasi tinggi, sedang, dan berisiko,
#     # sehingga lebih bermanfaat untuk analisis dan pengambilan keputusan akademik dibandingkan hanya dua kelompok yang bersifat biner.
#     # """)
# 
#     st.subheader("7. K-Means Clustering (Visualisasi dan Ringkasan)")
# 
#     from sklearn.cluster import KMeans
#     from sklearn.decomposition import PCA
# 
#     # Lakukan clustering
#     kmeans = KMeans(n_clusters=3, random_state=42)
#     df['Cluster'] = kmeans.fit_predict(X)
# 
#     # PCA untuk visualisasi
#     pca = PCA(n_components=2)
#     pca_result = pca.fit_transform(X)
#     df_pca = pd.DataFrame(pca_result, columns=['PCA1', 'PCA2'])
#     df_pca['Cluster'] = df['Cluster']
# 
#     fig_kmeans, ax_kmeans = plt.subplots(figsize=(8, 6))
#     sns.scatterplot(data=df_pca, x='PCA1', y='PCA2', hue='Cluster', palette='Set2', ax=ax_kmeans)
#     ax_kmeans.set_title("Visualisasi KMeans Clustering dengan PCA")
#     st.pyplot(fig_kmeans)
# 
#     # Rangkuman cluster
#     st.subheader("8. Rata-rata Tiap Fitur per Cluster")
#     cluster_features = ['Projects_Score', 'Final_Score', 'Midterm_Score',
#                         'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score']
#     cluster_summary = df.groupby('Cluster')[cluster_features].mean().reset_index()
#     st.dataframe(cluster_summary)
#     # Keterangan interpretasi setiap cluster
#     st.markdown("### Interpretasi Setiap Cluster")
# 
#     st.info("**Cluster 0**: Siswa yang rajin dan konsisten dalam tugas dan proyek, tetapi kurang unggul di ujian. Cocok disebut sebagai tipe “pekerja keras” yang mungkin tidak terlalu bagus dalam ujian tulis.")
# 
#     st.success("**Cluster 1**: Siswa dengan nilai ujian tinggi tapi tidak aktif dalam kelas dan tidak terlalu menonjol dalam tugas/proyek. Cocok disebut sebagai tipe independen dan pintar, tapi kurang terlibat secara aktif di kelas.")
# 
#     st.warning("**Cluster 2**: Siswa dengan nilai ujian tinggi tapi tidak terlalu menonjol dalam tugas proyek dan memiliki tingkat keaktifan paling tinggi di kelas. Cocok disebut sebagai tipe independen dan pintar.")
# 
# 
# # =================== Halaman 7: Input Score for Prediction ===================
# elif halaman == "Input Score for Prediction":
#     st.markdown("<br><h1 style='text-align: center; color: #FF7272;'>Input Score for Prediction</h1>", unsafe_allow_html=True)
#     st.markdown("<hr>", unsafe_allow_html=True)
# 
#     st.write("Masukkan nilai-nilai berikut untuk memprediksi kemungkinan kelulusan mahasiswa:")
# 
#     # Input user via slider
#     # input_data = {}
#     # input_data['Projects_Score'] = st.slider("Projects Score", 0.0, 100.0, 75.0)
#     # input_data['Final_Score'] = st.slider("Final Score", 0.0, 100.0, 75.0)
#     # input_data['Midterm_Score'] = st.slider("Midterm Score", 0.0, 100.0, 75.0)
#     # input_data['Assignments_Avg'] = st.slider("Assignments Average", 0.0, 100.0, 75.0)
#     # input_data['Quizzes_Avg'] = st.slider("Quizzes Average", 0.0, 100.0, 75.0)
#     # input_data['Participation_Score'] = st.slider("Participation Score", 0.0, 100.0, 75.0)
# 
#     # Input user via keyboard
#     input_data = {}
#     input_data['Projects_Score'] = st.number_input("Projects Score", min_value=0.0, max_value=100.0, value=75.0)
#     input_data['Final_Score'] = st.number_input("Final Score", min_value=0.0, max_value=100.0, value=75.0)
#     input_data['Midterm_Score'] = st.number_input("Midterm Score", min_value=0.0, max_value=100.0, value=75.0)
#     input_data['Assignments_Avg'] = st.number_input("Assignments Average", min_value=0.0, max_value=100.0, value=75.0)
#     input_data['Quizzes_Avg'] = st.number_input("Quizzes Average", min_value=0.0, max_value=100.0, value=75.0)
#     input_data['Participation_Score'] = st.number_input("Participation Score", min_value=0.0, max_value=100.0, value=75.0)
# 
# 
#     input_df = pd.DataFrame([input_data])
# 
#     st.subheader("1. Input Data yang Dimasukkan:")
#     st.dataframe(input_df)
# 
#     # Scaling input
#     input_scaled = scaler.transform(input_df)
# 
#     # Prediksi dengan kedua model
#     pred_lr = lr_model.predict(input_scaled)[0]
#     pred_rf = rf_model.predict(input_scaled)[0]
# 
#     pred_text_lr = "LULUS (PASS)" if pred_lr == 1 else "TIDAK LULUS (FAIL)"
#     pred_text_rf = "LULUS (PASS)" if pred_rf == 1 else "TIDAK LULUS (FAIL)"
# 
#     st.subheader("2. Hasil Prediksi Klasifikasi:")
#     col1, col2 = st.columns(2)
# 
#     with col1:
#         st.markdown("**Logistic Regression**")
#         if pred_lr == 1:
#             st.success(pred_text_lr)
#         else:
#             st.error(pred_text_lr)
# 
# 
#     with col2:
#         st.markdown("**Random Forest**")
#         if pred_rf == 1:
#             st.success(pred_text_rf)
#         else:
#             st.error(pred_text_rf)
# 
#     st.subheader("3. Cluster Mahasiswa berdasarkan Input (K-Means)")
# 
#     input_scaled = scaler.transform(input_df)
#     cluster_pred = kmeans.predict(input_scaled)[0]
# 
#     st.write(f"Mahasiswa ini diprediksi masuk ke dalam **Cluster {cluster_pred}** berdasarkan pola nilai mereka.")
# 
#     # Definisikan interpretasi cluster dan jenis box-nya
#     cluster_notes = {
#         0: {
#             "text": "→ Cluster 0: Siswa yang rajin dan konsisten dalam tugas dan proyek, tetapi kurang unggul di ujian. Cocok disebut sebagai tipe “pekerja keras” yang mungkin tidak terlalu bagus dalam ujian tulis.",
#             "type": "info"
#         },
#         1: {
#             "text": "→ Cluster 1: Siswa dengan nilai ujian tinggi tapi tidak aktif dalam kelas dan tidak terlalu menonjol dalam tugas/proyek. Cocok disebut sebagai tipe independen dan pintar, tapi kurang terlibat secara aktif di kelas.",
#             "type": "success"
#         },
#         2: {
#             "text": "→ Cluster 2: Siswa dengan nilai ujian tinggi tapi tidak terlalu menonjol dalam tugas proyek dan memiliki tingkat keaktifan paling tinggi di kelas. Cocok disebut sebagai tipe independen dan pintar.",
#             "type": "warning"
#         }
#     }
# 
#     # Tampilkan hasil sesuai cluster
#     note = cluster_notes.get(cluster_pred)
#     if note:
#         getattr(st, note["type"])(note["text"])

!ngrok config add-authtoken 2ynqi8VAsqDonVPIVk4QkSPnNbH_57kHX8Drhfas3qJtf5NBi

import subprocess
import time
from pyngrok import ngrok

!pkill -f streamlit
!pkill -f ngrok

# Jalankan Streamlit
process = subprocess.Popen(["streamlit", "run", "app.py"])

# Tunggu streamlit siap
time.sleep(5)

# Buka tunnel
url = ngrok.connect(8501)
print(f" Akses Dashboard Streamlit di sini: {url}")